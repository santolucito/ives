\section{Problem Formulation}
\label{problem}

\subsection{Naturalness}

\markk{HOW TO YOU USE THE TOOL}.

Program synthesis automatically builds a program from a specification.
For \ourTool/, the specification is a set, $Ex$, of pairs of input and output $(i,o)$.
We place a constraint on the example set that $Ex:\{(\tau_i,\tau_o)\}$, or more specifically $\forall (i,o) \in Ex,\ i:(\tau_i \in T) \land o:(\tau_o \in T)$.
In practice this a trivial constraint, achieved by requiring the user to provide the types explicitly via type annotation (as we do), using the compiler to infer types\cite{ghc}, or by inferring the types \cite{gulwani_popl15} based on regular expressions.

The goal in \textit{natural} program synthesis is synthesize programs that meet a specification with the simplest and most readable code.
As a formalization of simplicity and readability, we present a definition of naturalness.

The standard of measuring complexity (the inverse of naturalness) is cyclomatic complexity\cite{cyclo}.
Cyclomatic complexity is function, $\mathcal{CC}$ on the control flow graph of a section of code, $C$.
The function is $\mathcal{CC}(C) = E âˆ’ N + 2(P)$, where $E$, $N$, and $P$ are the edges, nodes and connected components respectively.
This function measures "the number of linearly independent paths" through a program, a crucial part of manipulating stateful variables.
However a this is not well-suited for pure functional languages that use branching in a more functional way.
For example, given two programs to compute absolute value, the "if" solution should be more natural, but using cycolmatic complexity verbatim means
\codeinline{f x = if x>=0 then x else x*-1} is more complex
\codeinline{f x = x * (fromEnum (x<0) * (-1) + fromEnum (x>0))}

Instead, we define naturalness to be the number of nodes in the abstract syntax tree.
This approach integrates cyclomatic complexity, because branching is still encoded as a measure of complexity.

%Our definition of naturalness matches well many techniques valued in functional community.
Currying fits under this definition of naturalness.
\markk{TODO - more} \codeinline{f = (1+)} is more natural than \codeinline{f x= 1 + x}.
This also favors predefined functions over generating new lambda terms.
Taking the code from Listing \ref{natSyn}, $\mathcal{N}($solution1$)$ has a naturalness score of 1/8, while $\mathcal{N}($solution2$)$ has a score of 1/3.

The problem is then to find an expression e, such that $\forall (i,o) \in Ex, e (i) = o \land max(\mathcal{N}(e))$.


\subsection{Enumeration}
In order to enumerate programs in order of naturalness, we will use a type directed enumeration.
We can immediately restrict our search space to exclude generated lambda terms (anonymous functions), as such terms will generally induce a very low naturalness score and explode the search space.
Our synthesis approach will then only be able to solve synthesis problems when a solution exists that only draws from a finite set of predefined expressions.

Let $E$ be the finite set of expressions exposed to the top-level module from user code, imported libraries, and the core library.
Our search space will be the set of permutations of well-typed applications of elements of $E$.

To determine if an expression is well-typed, let $T$ be the set of types (both inferred and explicitly declared) exposed to the top-level module from user code, imported libraries, and the core library.
A type environment $\Gamma$, is the set $\{e1 : \tau_1,\ ...,\ e_n : \tau_n\}$, where $e_{i} \in E$ and is of type $\tau_i \in T$.
$\tau_i$ may be a type variable, a concrete type
The set of well-typed expressions we consider, $\mathcal{G}$, is the set $\{e1 : \tau_1,\ ...,\ e_n : \tau_n\}$, where $e_i : \tau_i$ follows the usual rules of application for constructing well-typed expressions from $\Gamma$.
Notice that a cycle in types of $\Gamma$ will create an infinite set $\mathcal{G}$.

As an example, consider the following

\begin{gather*}
\Gamma = \{f:a\to b, g:b\to c, x:a\} \Rightarrow \\
\Gamma^2 = \{f:a\to b, g:b\to c, x:a, f(x):b\} \Rightarrow \\
\Gamma^3 = \mathcal{G} = \{f:a\to b, g:b\to c, x:a, f(x):b, g(f(x)):c\}
\end{gather*}


\subsection{Lifting Example Types}
While conceptually simple, enumerating all well-typed functions is wasteful.
As an example - if possible we need to prune the search space.
To do this, we can exploit an unstated assumption, but widely accepted approach, in existing programming-by-example work.
Usually, the example pair type is lifted into a function type in the trivial way.

\begin{flalign*}
lift\ (\tau_i, \tau_o) =\ \tau_i \to \tau_o
\end{flalign*}

However, a subtyping relation can create more specific types that will better prune the space.
The subtyping relation $A<:B$ means that any time type $B$ results in a well-typed program, so would type $A$ in place of $B$.
A subtyping relation induces a subset relation of terms of type $A$ in relation to the terms of type $B$.
For the purposes of this paper, we use $<:$ to mean only nontrivial subtyping rules - that is we do \textit{not} have $A<:A$.
Given $\mathcal{A} = \{ x | x:A\}$ and $\mathcal{B} = \{ x | x:B\}$, we have $\mathcal{A}\subseteq\mathcal{B}$.
Lifting the examples to a subtype of the trivial lifting can then yield a smaller search space.

\begin{flalign*}
lift'\ (\tau_i, \tau_o) <:\ \tau_i \to \tau_o\\
\end{flalign*}

Notice that we did not write out a full function for the subtype.
This would have implied a subtyping on the component types, specifically the inputs and outputs would be contravariant or covariant, respectively.
However, we do not wish to restrict the domain or range of the function, but only the size of function space.
So we must have the following

\begin{flalign*}
lift'\ (\tau_i, \tau_o) =&\ \tau^{s}_{i} \to \tau^{s}_{i} \nRightarrow\\
(\tau^{s}_{i} <: \tau_i)\ \lor&\ (\tau_o <: \tau^{s}_{o})\\
\end{flalign*}


As an demonstration of this approach, following the syntax from previous code samples, we demonstrate below the synthesis of \codeinline{map (+1)}. We provide examples of type \codeinline{([Int],[Int])}.
\begin{lstlisting}
exs :: [ [Int] :-> [Int] ]
exs = [
  [1]   :-> [2],
  [3,4] :-> [4,5] ]
\end{lstlisting}

Using the traditional approach, we would have the trivial lifting to the function type.
However, if we use $lift'$ instead, we would derive a more specific type.
This more specific type could be a refinement type, expressed here using the syntax of LiquidHaskell\cite{DBLP:conf/icfp/VazouSJVJ14}.
 
\begin{lstlisting}
exs        :: ([Int],[Int])
lift(exs)  :: [Int] -> [Int] 
lift'(exs) ::
  {x:[Int] -> y:[Int] | length x = length y}
\end{lstlisting}

Alternatively, we could also have derived the equally specific type using dependant types\cite{dependant_types}.
In this case, using the Agda language, we would need a definition of (\codeinline{Vec L a}) to describe the type of lists of length \codeinline{L} and elemental type \codeinline{a}.

\begin{lstlisting}
lift'(exs) ::
  {Vec L Int -> Vec L Int}
\end{lstlisting}

Notice that in either case, the target function type is a subtype of the trivial lifting, but we have not changed the number of inhabitants of the types of either the domain or range of the target function.

The approach presented here to efficiently solve natural synthesis is then: given a type environment $\Gamma$ and an example set $Ex:\{(\tau_i,\tau_o)\}$, enumerate $\mathcal{G}$ in order of naturalness, such that $e : lift'(\tau_i,\tau_o)$.
This list can then be checked in order to find an $e$ such that $\forall (i,o) \in Ex, e (i) = o$.

\subsection{function classification}
we need to assign all functions in $\mathcal{G}$ a refinement type in order to use the above result.
Hence we do offline analysis.


%This framing will draw the type of the target expression directly from the examples.

\subsection{Implementation Solution Space}\label{solnSpace}\

Our implementation restricts the search to the first level of application chains.
We are no longer using $\mathcal{G}$, but the more restricted space of $\mathcal{G}_I = \Gamma^2$.
In the context of the previous example, we now have 

\begin{gather*}
\Gamma = \{f:a\to b, g:b\to c, x:a\} \Rightarrow \\
\Gamma^2 = \mathcal{G}_I = \{f:a\to b, g:b\to c, x:a, f(x):b\}
\end{gather*}

we need this restriction because we are not using adga. we are building terms using haskell-src and re-engineering haskell syntax rules, which is a pain. Using agda could significantly reduce this burden by allowing us to program directly with types. However, we dont get all the libraries from haskell if we do that.

While this approach can work for first-order synthesis, we instead focus on data structure manipulation problems that can be solved with higher order functions.

We require all higher order functions to be of a unified type signature $ \star \to \tau_i \to \tau_o$, so that the signature of the solution program is a function mapping the input type to the output type. 
The type $\star$ is a type wildcard (from the partial type signatures of GHC~\cite{ghc}) that could be filled by a first-order function or a first-order function along with an initial value.
In the case of \codeinline{map :: (a -> b) -> [a] -> [b]}, the $\star$ matches \codeinline{(a -> b)}.
In the case of \codeinline{foldr :: (a -> b -> b) -> b -> [a] -> b)}, the $\star$ matches \codeinline{(a -> b -> b) -> b}.

This is generally a weak constraint, as good functional programming style dictates any higher order function that manipulates a data structure should have such a type signature.
This constraint is used to eliminate higher order functions such as \codeinline{flip:: (a ->b -> c) -> b -> a -> c}.
This function would complicate analysis and management of the search space, and in practice in not often necessary.

%\markk{the paragraph below makes no sense to me at all. better leave it out}

%The user must partially uncurry (collapsing trailing function arguments into a single tuple argument) any higher-order function they are interested in using during synthesis.
%This also means that any type variable appearing in the higher-order function must be accounted for in the input and output types so that all type variables in its signature can be resolved.
%This allows us to conclude that any types that are between the input and first order function will be static initial values, which can be assigned using the process described in Section \ref{makeFxns}.
%This is a simple procedure that makes use of the user's domain knowledge of which parameters to the function will be given by the examples; consider:

%\begin{lstlisting}
%zipWith' :: (a -> b -> c) -> ([a], [b]) -> [c]
%zipWith' f (xs,ys) = zipWith f xs ys
%\end{lstlisting}


The solutions \ourTool/ supports synthesizing are higher-order data structure manipulation programs.
The higher-order functions take a component function that is a first-order function, for example \codeinline{(+)}.


Generally, the component function is applied across the \textsf{input} data structure, which the \textsf{solution} uses to construct an \textsf{output} data structure or reduction.
As we will demonstrate in Section \ref{evaluation} this set is expressive enough to support the classic \texttt{map}, \texttt{filter}, and \texttt{fold} functions, as well as higher order functions found in imported modules and user-supplied code.

Our goal is to create a synthesis procedure that is easily portable across full implementations of functional languages (Haskell, OCaml, etc), so we prefer using a type directed approach to synthesis over explicit code analysis whenever possible.
This increases the portability and longevity of our system.
For this implementation we target Haskell, detailing the exact modifications needed to expand this to other languages in Section \ref{languageSupport}.

%Our algorithm does not explicitly try to fit component functions to the examples. Instead, we leverage a promising body of existing work in synthesizing top-level, first-order functions \cite{potential, reviewers}. While it is out of scope to go in to detail, we will briefly discuss the integration of these synthesis procedures in Section \ref{conclusions}.

%The liquidHaskell predicate applied to this signature will be of the effect of \texttt{len([a],[b]) = len([c])}.
